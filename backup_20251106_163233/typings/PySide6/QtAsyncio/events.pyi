"""
This type stub file was generated by pyright.
"""

import asyncio
import collections.abc
import concurrent.futures
import contextvars
import enum
from PySide6.QtCore import QCoreApplication, QObject, QThread
from . import futures, tasks
from typing import Any, Callable, TYPE_CHECKING, TypeVar, Unpack

__all__ = ["QAsyncioEventLoopPolicy", "QAsyncioEventLoop", "QAsyncioHandle", "QAsyncioTimerHandle"]
_T = TypeVar("_T")
if TYPE_CHECKING:
    _Ts = ...
    Context = contextvars.Context
else:
    ...
class QAsyncioExecutorWrapper(QObject):
    """
    Executors in asyncio allow running synchronous code in a separate thread or
    process without blocking the event loop or interrupting the asynchronous
    program flow. Callables are scheduled for execution by calling submit() or
    map() on an executor object.

    Executors require a bit of extra work for QtAsyncio, as we can't use
    naked Python threads; instead, we must make sure that the thread created
    by executor.submit() has an event loop. This is achieved by not submitting
    the callable directly, but a small wrapper that attaches a QEventLoop to
    the executor thread, and then creates a zero-delay singleshot timer to push
    the actual callable for the executor into this new event loop.
    """
    def __init__(self, func: Callable[[Unpack[_Ts]], Any], *args: Unpack[_Ts]) -> None:
        ...
    
    def do(self) -> Any:
        ...
    
    def exit(self): # -> None:
        ...
    


class QAsyncioEventLoopPolicy(asyncio.AbstractEventLoopPolicy):
    """
    Event loop policies are expected to be deprecated with Python 3.13, with
    subsequent removal in Python 3.15. At that point, part of the current
    logic of the QAsyncioEventLoopPolicy constructor will have to be moved
    to QtAsyncio.run() and/or to a loop factory class (to be provided as an
    argument to asyncio.run()). In particular, this concerns the logic of
    setting up the QCoreApplication and the SIGINT handler.

    More details:
    https://discuss.python.org/t/removing-the-asyncio-policy-system-asyncio-set-event-loop-policy-in-python-3-15/37553
    """
    def __init__(self, quit_qapp: bool = ..., handle_sigint: bool = ...) -> None:
        ...
    
    def get_event_loop(self) -> asyncio.AbstractEventLoop:
        ...
    
    def set_event_loop(self, loop: asyncio.AbstractEventLoop | None) -> None:
        ...
    
    def new_event_loop(self) -> asyncio.AbstractEventLoop:
        ...
    
    def get_child_watcher(self) -> asyncio.AbstractChildWatcher:
        ...
    
    def set_child_watcher(self, watcher: asyncio.AbstractChildWatcher) -> None:
        ...
    


class QAsyncioEventLoop(asyncio.BaseEventLoop, QObject):
    """
    Implements the asyncio API:
    https://docs.python.org/3/library/asyncio-eventloop.html
    """
    class ShutDownThread(QThread):
        """
        Used to shut down the default executor when calling
        shutdown_default_executor(). As the executor is a ThreadPoolExecutor,
        it must be shut down in a separate thread as all the threads from the
        thread pool must join, which we want to do without blocking the event
        loop.
        """
        def __init__(self, future: futures.QAsyncioFuture, loop: QAsyncioEventLoop) -> None:
            ...
        
        def run(self) -> None:
            ...
        
        def shutdown(self) -> None:
            ...
        
    
    
    def __init__(self, application: QCoreApplication, quit_qapp: bool = ...) -> None:
        ...
    
    def run_until_complete(self, future: futures.QAsyncioFuture) -> Any:
        ...
    
    def run_forever(self) -> None:
        ...
    
    def stop(self) -> None:
        ...
    
    def is_running(self) -> bool:
        ...
    
    def is_closed(self) -> bool:
        ...
    
    def close(self) -> None:
        ...
    
    async def shutdown_asyncgens(self) -> None:
        ...
    
    async def shutdown_default_executor(self, timeout: int | float | None = ...) -> None:
        ...
    
    def call_soon(self, callback: Callable[[Unpack[_Ts]], object], *args: Unpack[_Ts], context: Context | None = ...) -> asyncio.Handle:
        ...
    
    def call_soon_threadsafe(self, callback: Callable[[Unpack[_Ts]], object], *args: Unpack[_Ts], context: Context | None = ...) -> asyncio.Handle:
        ...
    
    def call_later(self, delay: float, callback: Callable[[Unpack[_Ts]], object], *args: Unpack[_Ts], context: Context | None = ...) -> asyncio.TimerHandle:
        ...
    
    def call_at(self, when: float, callback: Callable[[Unpack[_Ts]], object], *args: Unpack[_Ts], context: Context | None = ...) -> asyncio.TimerHandle:
        ...
    
    def time(self) -> float:
        ...
    
    def create_future(self) -> futures.QAsyncioFuture:
        ...
    
    def create_task(self, coro: collections.abc.Generator | collections.abc.Coroutine, *, name: str | None = ..., context: contextvars.Context | None = ...) -> tasks.QAsyncioTask:
        ...
    
    def set_task_factory(self, factory: Callable | None) -> None:
        ...
    
    def get_task_factory(self) -> Callable | None:
        ...
    
    async def create_connection(self, protocol_factory, host=..., port=..., *, ssl=..., family=..., proto=..., flags=..., sock=..., local_addr=..., server_hostname=..., ssl_handshake_timeout=..., ssl_shutdown_timeout=..., happy_eyeballs_delay=..., interleave=...):
        ...
    
    async def create_datagram_endpoint(self, protocol_factory, local_addr=..., remote_addr=..., *, family=..., proto=..., flags=..., reuse_address=..., reuse_port=..., allow_broadcast=..., sock=...):
        ...
    
    async def create_unix_connection(self, protocol_factory, path=..., *, ssl=..., sock=..., server_hostname=..., ssl_handshake_timeout=..., ssl_shutdown_timeout=...):
        ...
    
    async def create_server(self, protocol_factory, host=..., port=..., *, family=..., flags=..., sock=..., backlog=..., ssl=..., reuse_address=..., reuse_port=..., ssl_handshake_timeout=..., ssl_shutdown_timeout=..., start_serving=...):
        ...
    
    async def create_unix_server(self, protocol_factory, path=..., *, sock=..., backlog=..., ssl=..., ssl_handshake_timeout=..., ssl_shutdown_timeout=..., start_serving=...):
        ...
    
    async def connect_accepted_socket(self, protocol_factory, sock, *, ssl=..., ssl_handshake_timeout=..., ssl_shutdown_timeout=...):
        ...
    
    async def sendfile(self, transport, file, offset=..., count=..., *, fallback=...):
        ...
    
    async def start_tls(self, transport, protocol, sslcontext, *, server_side=..., server_hostname=..., ssl_handshake_timeout=..., ssl_shutdown_timeout=...):
        ...
    
    def add_reader(self, fd, callback, *args):
        ...
    
    def remove_reader(self, fd):
        ...
    
    def add_writer(self, fd, callback, *args):
        ...
    
    def remove_writer(self, fd):
        ...
    
    async def sock_recv(self, sock, nbytes):
        ...
    
    async def sock_recv_into(self, sock, buf):
        ...
    
    async def sock_recvfrom(self, sock, bufsize):
        ...
    
    async def sock_recvfrom_into(self, sock, buf, nbytes=...):
        ...
    
    async def sock_sendall(self, sock, data):
        ...
    
    async def sock_sendto(self, sock, data, address):
        ...
    
    async def sock_connect(self, sock, address):
        ...
    
    async def sock_accept(self, sock):
        ...
    
    async def sock_sendfile(self, sock, file, offset=..., count=..., *, fallback=...):
        ...
    
    async def getaddrinfo(self, host, port, *, family=..., type=..., proto=..., flags=...):
        ...
    
    async def getnameinfo(self, sockaddr, flags=...):
        ...
    
    async def connect_read_pipe(self, protocol_factory, pipe):
        ...
    
    async def connect_write_pipe(self, protocol_factory, pipe):
        ...
    
    def add_signal_handler(self, sig, callback, *args):
        ...
    
    def remove_signal_handler(self, sig):
        ...
    
    def run_in_executor(self, executor: concurrent.futures.ThreadPoolExecutor | None, func: Callable[[Unpack[_Ts]], _T], *args: Unpack[_Ts]) -> asyncio.Future[_T]:
        ...
    
    def set_default_executor(self, executor: concurrent.futures.ThreadPoolExecutor | None) -> None:
        ...
    
    def set_exception_handler(self, handler: Callable | None) -> None:
        ...
    
    def get_exception_handler(self) -> Callable | None:
        ...
    
    def default_exception_handler(self, context: dict[str, Any]) -> None:
        ...
    
    def call_exception_handler(self, context: dict[str, Any]) -> None:
        ...
    
    def get_debug(self) -> bool:
        ...
    
    def set_debug(self, enabled: bool) -> None:
        ...
    
    async def subprocess_exec(self, protocol_factory, *args, stdin=..., stdout=..., stderr=..., **kwargs):
        ...
    
    async def subprocess_shell(self, protocol_factory, cmd, *, stdin=..., stdout=..., stderr=..., **kwargs):
        ...
    


class QAsyncioHandle:
    """
    The handle enqueues a callback to be executed by the event loop, and allows
    for this callback to be cancelled before it is executed. This callback will
    typically execute the step function for a task. This makes the handle one
    of the main components of asyncio.
    """
    class HandleState(enum.Enum):
        PENDING = ...
        CANCELLED = ...
        DONE = ...
    
    
    def __init__(self, callback: Callable, args: tuple, loop: QAsyncioEventLoop, context: contextvars.Context | None, is_threadsafe: bool | None = ...) -> None:
        ...
    
    def cancel(self) -> None:
        ...
    
    def cancelled(self) -> bool:
        ...
    


class QAsyncioTimerHandle(QAsyncioHandle, asyncio.TimerHandle):
    def __init__(self, when: float, callback: Callable, args: tuple, loop: QAsyncioEventLoop, context: contextvars.Context | None, is_threadsafe: bool | None = ...) -> None:
        ...
    
    def when(self) -> float:
        ...
    


