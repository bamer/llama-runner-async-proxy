import logging
import asyncio
from fastapi import FastAPI
from uvicorn import Config, Server

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_ollama_service():
    logger.info("üöÄ Test du service Ollama proxy simplifi√©")
    
    try:
        logger.info("üîß Cr√©ation application FastAPI pour Ollama")
        app = FastAPI()
        
        @app.get("/health")
        async def health():
            return {"status": "ok", "service": "ollama-proxy-test"}
        
        @app.get("/api/tags")
        async def get_tags():
            return {
                "models": [
                    {
                        "name": "test-model:latest",
                        "model": "test-model",
                        "size": 1000000,
                        "digest": "test-digest"
                    }
                ]
            }
        
        @app.post("/api/generate")
        async def generate(request: dict):
            return {
                "model": request.get("model", "test-model"),
                "created_at": "2025-11-10T01:50:00Z",
                "response": "Ceci est une r√©ponse de test du proxy Ollama",
                "done": True
            }
        
        logger.info("üîß Configuration du serveur Ollama sur port 11434")
        config = Config(
            app=app,
            host="0.0.0.0",
            port=11434,
            log_level="debug"
        )
        
        server = Server(config)
        logger.info("‚ñ∂Ô∏è D√©marrage du serveur Ollama")
        
        server_task = asyncio.create_task(server.serve())
        logger.info("‚úÖ Serveur Ollama d√©marr√© avec succ√®s")
        
        # Attendre un peu pour laisser le temps au serveur de d√©marrer
        await asyncio.sleep(2)
        
        logger.info("üîç Test des endpoints Ollama")
        import httpx
        async with httpx.AsyncClient() as client:
            # Test health
            response = await client.get("http://localhost:11434/health")
            logger.info(f"‚úÖ Health: {response.status_code} - {response.json()}")
            
            # Test tags
            response = await client.get("http://localhost:11434/api/tags")
            logger.info(f"‚úÖ Tags: {response.status_code} - {response.json()}")
            
            # Test generate
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={"model": "test-model", "prompt": "Bonjour"}
            )
            logger.info(f"‚úÖ Generate: {response.status_code} - {response.json()}")
        
        # Arr√™ter le serveur
        logger.info("üõë Arr√™t du serveur Ollama")
        server.should_exit = True
        await server_task
        
        logger.info("üéâ Test Ollama r√©ussi !")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Erreur Ollama: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

if __name__ == "__main__":
    logger.info("üèÅ TEST DU SERVICE OLLAMA PROXY")
    
    try:
        loop = asyncio.get_event_loop()
        success = loop.run_until_complete(test_ollama_service())
        logger.info(f"‚ú® R√©sultat Ollama: {'SUCC√àS' if success else '√âCHEC'}")
        loop.close()
    except Exception as e:
        logger.error(f"‚ùå Erreur fatale Ollama: {e}")
        import traceback
        logger.error(traceback.format_exc())