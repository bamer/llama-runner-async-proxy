#!/usr/bin/env python3

# Simple launcher script for Llama Runner Async Proxy
import os
import sys

print("Llama Runner Async Proxy")
print("========================")

# Show usage instructions
print("\nTo run the application:")
print("cd /home/bamer/llama-runner-async-proxy")
print("/home/bamer/llama-runner-async-proxy/dev-venv/bin/python app/main.py")

print("\nTo access the monitoring page:")
print("Browse to http://localhost:8081/monitoring")

print("\nTo access model configuration:")
print("Browse to http://localhost:8081/")

print("\nDocumentation available in docs/README.md")
