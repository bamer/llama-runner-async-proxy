{
  "default_parameters": {
    "ctx_size": 128000,
    "temp": 0.7,
    "batch_size": 1024,
    "ubatch_size": 512,
    "threads": 10,
    "mlock": true,
    "no_mmap": true,
    "flash_attn": "on",
    "port": 8134,
    "host": "127.0.0.1"
  },
  "runtimes": {
    "llama-server": {
      "runtime": "/home/bamer/llama.cpp/build/bin/llama-server",
      "supports_tools": true
    }
  },
  "models": {},
  "default_model": null
}