{
  "models": {
    "DeepSeek-Coder": {
      "name": "DeepSeek-Coder",
      "path": "/media/bamer/crucial MX300/llm/llama/models/test1.gguf",
      "filename": "test1.gguf",
      "format": "gguf",
      "size": 10000000000,
      "sizeGB": "9.31",
      "status": "ready",
      "discovered_at": "2025-12-03T03:13:29.036Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:13:29.037Z"
    },
    "DeepSeek-Coder-V2-Lite-Instruct.Q4_K": {
      "name": "DeepSeek-Coder-V2-Lite-Instruct.Q4_K",
      "path": "/media/bamer/crucial MX300/llm/llama/models/DeepSeek-Coder-V2-Lite-Instruct.Q4_K-gguf/DeepSeek-Coder-V2-Lite-Instruct.Q4_K.gguf",
      "filename": "DeepSeek-Coder-V2-Lite-Instruct.Q4_K.gguf",
      "format": "gguf",
      "size": 10364416768,
      "sizeGB": "9.65",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.089Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.090Z"
    },
    "GPT-OSS-Code-Reasoning-20B.Q4_K_S": {
      "name": "GPT-OSS-Code-Reasoning-20B.Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/GPT-OSS-Code-Reasoning-20B.Q4_K_S-gguf/GPT-OSS-Code-Reasoning-20B.Q4_K_S.gguf",
      "filename": "GPT-OSS-Code-Reasoning-20B.Q4_K_S.gguf",
      "format": "gguf",
      "size": 14654241952,
      "sizeGB": "13.65",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.092Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.092Z"
    },
    "GPT-OSS-Code-Reasoning-20B.Q8_0": {
      "name": "GPT-OSS-Code-Reasoning-20B.Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/GPT-OSS-Code-Reasoning-20B.Q8_0-gguf/GPT-OSS-Code-Reasoning-20B.Q8_0.gguf",
      "filename": "GPT-OSS-Code-Reasoning-20B.Q8_0.gguf",
      "format": "gguf",
      "size": 22261911712,
      "sizeGB": "20.73",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.093Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.093Z"
    },
    "model": {
      "name": "model",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4_0-h-tiny-IQ4_XS/model.gguf",
      "filename": "model.gguf",
      "format": "gguf",
      "size": 3788906656,
      "sizeGB": "3.53",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.144Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.145Z"
    },
    "JanusCoderV-7B.i1-Q4_K_S": {
      "name": "JanusCoderV-7B.i1-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/JanusCoderV-7B-i1-GGUF/JanusCoderV-7B.i1-Q4_K_S.gguf",
      "filename": "JanusCoderV-7B.i1-Q4_K_S.gguf",
      "format": "gguf",
      "size": 4457768224,
      "sizeGB": "4.15",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.096Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.097Z"
    },
    "nomic-embed-text-v1.5-Q8_0": {
      "name": "nomic-embed-text-v1.5-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Nomic-embed-text-v1.5-Embedding-GGUF/nomic-embed-text-v1.5-Q8_0.gguf",
      "filename": "nomic-embed-text-v1.5-Q8_0.gguf",
      "format": "gguf",
      "size": 146146528,
      "sizeGB": "0.14",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.098Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.098Z"
    },
    "nomic-embed-text-v1.5-f16": {
      "name": "nomic-embed-text-v1.5-f16",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Nomic-embed-text-v1.5-Embedding-GGUF/nomic-embed-text-v1.5-f16.gguf",
      "filename": "nomic-embed-text-v1.5-f16.gguf",
      "format": "gguf",
      "size": 274290656,
      "sizeGB": "0.26",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.099Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.099Z"
    },
    "nomic-embed-text-v1.5.f16": {
      "name": "nomic-embed-text-v1.5.f16",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Nomic-embed-text-v1.5-Embedding-GGUF/nomic-embed-text-v1.5.f16.gguf",
      "filename": "nomic-embed-text-v1.5.f16.gguf",
      "format": "gguf",
      "size": 274290560,
      "sizeGB": "0.26",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.100Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.100Z"
    },
    "Olmo-3-7B-Think-SFT.Q6_K": {
      "name": "Olmo-3-7B-Think-SFT.Q6_K",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Olmo-3-7B-Think-SFT.Q6_K-gguf/Olmo-3-7B-Think-SFT.Q6_K.gguf",
      "filename": "Olmo-3-7B-Think-SFT.Q6_K.gguf",
      "format": "gguf",
      "size": 5991892416,
      "sizeGB": "5.58",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.101Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.101Z"
    },
    "Qwen2.5-7B-Instruct-Q4_K_M": {
      "name": "Qwen2.5-7B-Instruct-Q4_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-7B-Instruct-Q4_K_M-GGUF/Qwen2.5-7B-Instruct-Q4_K_M.gguf",
      "filename": "Qwen2.5-7B-Instruct-Q4_K_M.gguf",
      "format": "gguf",
      "size": 4683073952,
      "sizeGB": "4.36",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.103Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.103Z"
    },
    "qwen2.5-coder-1.5b-q8_0": {
      "name": "qwen2.5-coder-1.5b-q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-Coder-1.5B-Q8_0-GGUF/qwen2.5-coder-1.5b-q8_0.gguf",
      "filename": "qwen2.5-coder-1.5b-q8_0.gguf",
      "format": "gguf",
      "size": 1646573056,
      "sizeGB": "1.53",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.104Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.105Z"
    },
    "Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M": {
      "name": "Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M-GGUF/Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M.gguf",
      "filename": "Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M.gguf",
      "format": "gguf",
      "size": 5444832064,
      "sizeGB": "5.07",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.106Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.106Z"
    },
    "Qwen2.5-Omni-3B-Q8_0": {
      "name": "Qwen2.5-Omni-3B-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-Omni-3B-GGUF/Qwen2.5-Omni-3B-Q8_0.gguf",
      "filename": "Qwen2.5-Omni-3B-Q8_0.gguf",
      "format": "gguf",
      "size": 3616087360,
      "sizeGB": "3.37",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.107Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.108Z"
    },
    "Qwen2.5-VL-7B-Instruct-Q4_K_S": {
      "name": "Qwen2.5-VL-7B-Instruct-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-VL-7B-Instruct-GGUF/Qwen2.5-VL-7B-Instruct-Q4_K_S.gguf",
      "filename": "Qwen2.5-VL-7B-Instruct-Q4_K_S.gguf",
      "format": "gguf",
      "size": 4457767808,
      "sizeGB": "4.15",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.109Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.109Z"
    },
    "Qwen3-0.6B-Q4_K_S": {
      "name": "Qwen3-0.6B-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-0.6B-GGUF/Qwen3-0.6B-Q4_K_S.gguf",
      "filename": "Qwen3-0.6B-Q4_K_S.gguf",
      "format": "gguf",
      "size": 383270592,
      "sizeGB": "0.36",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.110Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.110Z"
    },
    "Qwen3-0.6B-Q8_0": {
      "name": "Qwen3-0.6B-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-0.6B-GGUF/Qwen3-0.6B-Q8_0.gguf",
      "filename": "Qwen3-0.6B-Q8_0.gguf",
      "format": "gguf",
      "size": 639446688,
      "sizeGB": "0.60",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.111Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.111Z"
    },
    "Qwen3-1.7B-Q4_K_S": {
      "name": "Qwen3-1.7B-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-1.7B-GGUF/Qwen3-1.7B-Q4_K_S.gguf",
      "filename": "Qwen3-1.7B-Q4_K_S.gguf",
      "format": "gguf",
      "size": 1060190784,
      "sizeGB": "0.99",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.112Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.113Z"
    },
    "Qwen3-1.7B-Q8_0": {
      "name": "Qwen3-1.7B-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-1.7B-Q8_0-GGUF/Qwen3-1.7B-Q8_0.gguf",
      "filename": "Qwen3-1.7B-Q8_0.gguf",
      "format": "gguf",
      "size": 1834426016,
      "sizeGB": "1.71",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.114Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.114Z"
    },
    "Qwen3-14B-Q4_K_S": {
      "name": "Qwen3-14B-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-14B-GGUF/Qwen3-14B-Q4_K_S.gguf",
      "filename": "Qwen3-14B-Q4_K_S.gguf",
      "format": "gguf",
      "size": 8573476224,
      "sizeGB": "7.98",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.116Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.116Z"
    },
    "Qwen3-4B-Thinking-2507-Q4_K_S": {
      "name": "Qwen3-4B-Thinking-2507-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-4B-Thinking-2507-Q4_K_S-GGUF/Qwen3-4B-Thinking-2507-Q4_K_S.gguf",
      "filename": "Qwen3-4B-Thinking-2507-Q4_K_S.gguf",
      "format": "gguf",
      "size": 2383309952,
      "sizeGB": "2.22",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.117Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.118Z"
    },
    "Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S": {
      "name": "Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S-gguf/Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S.gguf",
      "filename": "Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S.gguf",
      "format": "gguf",
      "size": 10740661760,
      "sizeGB": "10.00",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.118Z",
      "ctx_size": 128000,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S-gguf",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 25,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": true,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T11:59:53.088Z",
      "no_mmap": true,
      "cache_reuse": 256,
      "ggml_cuda_enable_unified_memory": true
    },
    "Qwen3-Coder-30B-A3B-Instruct-Q4_K_S": {
      "name": "Qwen3-Coder-30B-A3B-Instruct-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-Coder-30B-A3B-Instruct-Q4_K_S-GGUF/Qwen3-Coder-30B-A3B-Instruct-Q4_K_S.gguf",
      "filename": "Qwen3-Coder-30B-A3B-Instruct-Q4_K_S.gguf",
      "format": "gguf",
      "size": 17456012448,
      "sizeGB": "16.26",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.120Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.120Z"
    },
    "Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1": {
      "name": "Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1-gguf/Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1.gguf",
      "filename": "Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1.gguf",
      "format": "gguf",
      "size": 7539550848,
      "sizeGB": "7.02",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.121Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.122Z"
    },
    "Qwen3-VL-2B-Thinking-1M-Q4_K_S": {
      "name": "Qwen3-VL-2B-Thinking-1M-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-VL-2B-Thinking-1M-GGUF/Qwen3-VL-2B-Thinking-1M-Q4_K_S.gguf",
      "filename": "Qwen3-VL-2B-Thinking-1M-Q4_K_S.gguf",
      "format": "gguf",
      "size": 1060192576,
      "sizeGB": "0.99",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.123Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.124Z"
    },
    "Qwen3-VL-8B-Thinking-Q4_K_S": {
      "name": "Qwen3-VL-8B-Thinking-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-VL-8B-Thinking-GGUF/Qwen3-VL-8B-Thinking-Q4_K_S.gguf",
      "filename": "Qwen3-VL-8B-Thinking-Q4_K_S.gguf",
      "format": "gguf",
      "size": 4802014496,
      "sizeGB": "4.47",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.125Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.125Z"
    },
    "Qwen3-VL-8B-Thinking.Q4_K": {
      "name": "Qwen3-VL-8B-Thinking.Q4_K",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-VL-8B-Thinking.Q4_K-GGUF/Qwen3-VL-8B-Thinking.Q4_K.gguf",
      "filename": "Qwen3-VL-8B-Thinking.Q4_K.gguf",
      "format": "gguf",
      "size": 4608376544,
      "sizeGB": "4.29",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.127Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.127Z"
    },
    "Seed-Coder-8B-Reasoning-UD-Q5_K_XL": {
      "name": "Seed-Coder-8B-Reasoning-UD-Q5_K_XL",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Seed-Coder-8B-Reasoning-GGUF/Seed-Coder-8B-Reasoning-UD-Q5_K_XL.gguf",
      "filename": "Seed-Coder-8B-Reasoning-UD-Q5_K_XL.gguf",
      "format": "gguf",
      "size": 5888349504,
      "sizeGB": "5.48",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.130Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.130Z"
    },
    "fluentlyqwen3-coder-4b-q8_0": {
      "name": "fluentlyqwen3-coder-4b-q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/fluentlyqwen3-coder-4b-q8_0-gguf/fluentlyqwen3-coder-4b-q8_0.gguf",
      "filename": "fluentlyqwen3-coder-4b-q8_0.gguf",
      "format": "gguf",
      "size": 4280401376,
      "sizeGB": "3.99",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.132Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.133Z"
    },
    "gemma-3-1b-it-Q4_K_M": {
      "name": "gemma-3-1b-it-Q4_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/gemma-3-1b-it-Q4_K_M-gguf/gemma-3-1b-it-Q4_K_M.gguf",
      "filename": "gemma-3-1b-it-Q4_K_M.gguf",
      "format": "gguf",
      "size": 806058240,
      "sizeGB": "0.75",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.135Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.136Z"
    },
    "granite-4.0-h-1b-Q4_K_S": {
      "name": "granite-4.0-h-1b-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4.0-h-1b-GGUF/granite-4.0-h-1b-Q4_K_S.gguf",
      "filename": "granite-4.0-h-1b-Q4_K_S.gguf",
      "format": "gguf",
      "size": 872642112,
      "sizeGB": "0.81",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.138Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.139Z"
    },
    "granite-4.0-h-1b-Q8_0": {
      "name": "granite-4.0-h-1b-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4.0-h-1b-GGUF/granite-4.0-h-1b-Q8_0.gguf",
      "filename": "granite-4.0-h-1b-Q8_0.gguf",
      "format": "gguf",
      "size": 1558926912,
      "sizeGB": "1.45",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.140Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.140Z"
    },
    "granite-4.0-h-350m-Q8_0": {
      "name": "granite-4.0-h-350m-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4.0-h-350m-GGUF/granite-4.0-h-350m-Q8_0.gguf",
      "filename": "granite-4.0-h-350m-Q8_0.gguf",
      "format": "gguf",
      "size": 366196000,
      "sizeGB": "0.34",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.141Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.142Z"
    },
    "magnus-coder.Q4_K_M": {
      "name": "magnus-coder.Q4_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/magnus-coder.Q4_K_M.gguf/magnus-coder.Q4_K_M.gguf",
      "filename": "magnus-coder.Q4_K_M.gguf",
      "format": "gguf",
      "size": 4683084294,
      "sizeGB": "4.36",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.146Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.146Z"
    },
    "miromind-ai_MiroThinker-v1.0-8B-Q6_K_L": {
      "name": "miromind-ai_MiroThinker-v1.0-8B-Q6_K_L",
      "path": "/media/bamer/crucial MX300/llm/llama/models/miromind-ai_MiroThinker-v1.0-8B-Q6_K_L-gguf/miromind-ai_MiroThinker-v1.0-8B-Q6_K_L.gguf",
      "filename": "miromind-ai_MiroThinker-v1.0-8B-Q6_K_L.gguf",
      "format": "gguf",
      "size": 7027341312,
      "sizeGB": "6.54",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.147Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.148Z"
    },
    "neutss-air-BF16": {
      "name": "neutss-air-BF16",
      "path": "/media/bamer/crucial MX300/llm/llama/models/neutts-air/neutss-air-BF16.gguf",
      "filename": "neutss-air-BF16.gguf",
      "format": "gguf",
      "size": 1503776000,
      "sizeGB": "1.40",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.150Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.151Z"
    },
    "nvidia-nemotron-nano-9b-v2-q4_k_m": {
      "name": "nvidia-nemotron-nano-9b-v2-q4_k_m",
      "path": "/media/bamer/crucial MX300/llm/llama/models/nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S-gguf/nvidia-nemotron-nano-9b-v2-q4_k_m.gguf",
      "filename": "nvidia-nemotron-nano-9b-v2-q4_k_m.gguf",
      "format": "gguf",
      "size": 6525629280,
      "sizeGB": "6.08",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.152Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.153Z"
    },
    "nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S": {
      "name": "nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S-gguf/nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S.gguf",
      "filename": "nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S.gguf",
      "format": "gguf",
      "size": 8567895552,
      "sizeGB": "7.98",
      "status": "ready",
      "discovered_at": "2025-12-03T03:43:47.154Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:43:47.155Z"
    }
  },
  "paths": {
    "modelsDirectory": "/media/bamer/crucial MX300/llm/llama/models"
  },
  "proxies": {
    "lmstudio": {
      "enabled": true
    },
    "ollama": {
      "enabled": true
    }
  },
  "monitoring": {
    "enableGpuMonitoring": true,
    "enableDetailedLogging": true
  }
}