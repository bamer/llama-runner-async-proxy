{
  "models": {
    "DeepSeek-Coder": {
      "name": "DeepSeek-Coder",
      "path": "/media/bamer/crucial MX300/llm/llama/models/test1.gguf",
      "filename": "test1.gguf",
      "format": "gguf",
      "size": 10000000000,
      "sizeGB": "9.31",
      "status": "ready",
      "discovered_at": "2025-12-03T03:13:29.036Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "mlock": false,
      "mmap": true,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "use_mmap": true,
      "use_mlock": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "log_all": false,
      "verbose": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T03:13:29.037Z"
    },
    "DeepSeek-Coder-V2-Lite-Instruct.Q4_K": {
      "name": "DeepSeek-Coder-V2-Lite-Instruct.Q4_K",
      "path": "/media/bamer/crucial MX300/llm/llama/models/DeepSeek-Coder-V2-Lite-Instruct.Q4_K-gguf/DeepSeek-Coder-V2-Lite-Instruct.Q4_K.gguf",
      "filename": "DeepSeek-Coder-V2-Lite-Instruct.Q4_K.gguf",
      "format": "gguf",
      "size": 10364416768,
      "sizeGB": "9.65",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.751Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.753Z"
    },
    "GPT-OSS-Code-Reasoning-20B.Q4_K_S": {
      "name": "GPT-OSS-Code-Reasoning-20B.Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/GPT-OSS-Code-Reasoning-20B.Q4_K_S-gguf/GPT-OSS-Code-Reasoning-20B.Q4_K_S.gguf",
      "filename": "GPT-OSS-Code-Reasoning-20B.Q4_K_S.gguf",
      "format": "gguf",
      "size": 14654241952,
      "sizeGB": "13.65",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.755Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.756Z"
    },
    "GPT-OSS-Code-Reasoning-20B.Q8_0": {
      "name": "GPT-OSS-Code-Reasoning-20B.Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/GPT-OSS-Code-Reasoning-20B.Q8_0-gguf/GPT-OSS-Code-Reasoning-20B.Q8_0.gguf",
      "filename": "GPT-OSS-Code-Reasoning-20B.Q8_0.gguf",
      "format": "gguf",
      "size": 22261911712,
      "sizeGB": "20.73",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.759Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.761Z"
    },
    "model": {
      "name": "model",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4_0-h-tiny-IQ4_XS/model.gguf",
      "filename": "model.gguf",
      "format": "gguf",
      "size": 3788906656,
      "sizeGB": "3.53",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.830Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.830Z"
    },
    "JanusCoderV-7B.i1-Q4_K_S": {
      "name": "JanusCoderV-7B.i1-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/JanusCoderV-7B-i1-GGUF/JanusCoderV-7B.i1-Q4_K_S.gguf",
      "filename": "JanusCoderV-7B.i1-Q4_K_S.gguf",
      "format": "gguf",
      "size": 4457768224,
      "sizeGB": "4.15",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.768Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.769Z"
    },
    "nomic-embed-text-v1.5-Q8_0": {
      "name": "nomic-embed-text-v1.5-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Nomic-embed-text-v1.5-Embedding-GGUF/nomic-embed-text-v1.5-Q8_0.gguf",
      "filename": "nomic-embed-text-v1.5-Q8_0.gguf",
      "format": "gguf",
      "size": 146146528,
      "sizeGB": "0.14",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.772Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.773Z"
    },
    "nomic-embed-text-v1.5-f16": {
      "name": "nomic-embed-text-v1.5-f16",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Nomic-embed-text-v1.5-Embedding-GGUF/nomic-embed-text-v1.5-f16.gguf",
      "filename": "nomic-embed-text-v1.5-f16.gguf",
      "format": "gguf",
      "size": 274290656,
      "sizeGB": "0.26",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.776Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.776Z"
    },
    "nomic-embed-text-v1.5.f16": {
      "name": "nomic-embed-text-v1.5.f16",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Nomic-embed-text-v1.5-Embedding-GGUF/nomic-embed-text-v1.5.f16.gguf",
      "filename": "nomic-embed-text-v1.5.f16.gguf",
      "format": "gguf",
      "size": 274290560,
      "sizeGB": "0.26",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.778Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.779Z"
    },
    "Olmo-3-7B-Think-SFT.Q6_K": {
      "name": "Olmo-3-7B-Think-SFT.Q6_K",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Olmo-3-7B-Think-SFT.Q6_K-gguf/Olmo-3-7B-Think-SFT.Q6_K.gguf",
      "filename": "Olmo-3-7B-Think-SFT.Q6_K.gguf",
      "format": "gguf",
      "size": 5991892416,
      "sizeGB": "5.58",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.781Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.783Z"
    },
    "Qwen2.5-7B-Instruct-Q4_K_M": {
      "name": "Qwen2.5-7B-Instruct-Q4_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-7B-Instruct-Q4_K_M-GGUF/Qwen2.5-7B-Instruct-Q4_K_M.gguf",
      "filename": "Qwen2.5-7B-Instruct-Q4_K_M.gguf",
      "format": "gguf",
      "size": 4683073952,
      "sizeGB": "4.36",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.789Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.790Z"
    },
    "qwen2.5-coder-1.5b-q8_0": {
      "name": "qwen2.5-coder-1.5b-q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-Coder-1.5B-Q8_0-GGUF/qwen2.5-coder-1.5b-q8_0.gguf",
      "filename": "qwen2.5-coder-1.5b-q8_0.gguf",
      "format": "gguf",
      "size": 1646573056,
      "sizeGB": "1.53",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.792Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.793Z"
    },
    "Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M": {
      "name": "Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M-GGUF/Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M.gguf",
      "filename": "Qwen2.5-Coder-7B-Instruct-abliterated.Q5_K_M.gguf",
      "format": "gguf",
      "size": 5444832064,
      "sizeGB": "5.07",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.796Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.796Z"
    },
    "Qwen2.5-Omni-3B-Q8_0": {
      "name": "Qwen2.5-Omni-3B-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-Omni-3B-GGUF/Qwen2.5-Omni-3B-Q8_0.gguf",
      "filename": "Qwen2.5-Omni-3B-Q8_0.gguf",
      "format": "gguf",
      "size": 3616087360,
      "sizeGB": "3.37",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.798Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.799Z"
    },
    "Qwen2.5-VL-7B-Instruct-Q4_K_S": {
      "name": "Qwen2.5-VL-7B-Instruct-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen2.5-VL-7B-Instruct-GGUF/Qwen2.5-VL-7B-Instruct-Q4_K_S.gguf",
      "filename": "Qwen2.5-VL-7B-Instruct-Q4_K_S.gguf",
      "format": "gguf",
      "size": 4457767808,
      "sizeGB": "4.15",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.800Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.801Z"
    },
    "Qwen3-0.6B-Q4_K_S": {
      "name": "Qwen3-0.6B-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-0.6B-GGUF/Qwen3-0.6B-Q4_K_S.gguf",
      "filename": "Qwen3-0.6B-Q4_K_S.gguf",
      "format": "gguf",
      "size": 383270592,
      "sizeGB": "0.36",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.802Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.803Z"
    },
    "Qwen3-0.6B-Q8_0": {
      "name": "Qwen3-0.6B-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-0.6B-GGUF/Qwen3-0.6B-Q8_0.gguf",
      "filename": "Qwen3-0.6B-Q8_0.gguf",
      "format": "gguf",
      "size": 639446688,
      "sizeGB": "0.60",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.804Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.805Z"
    },
    "Qwen3-1.7B-Q4_K_S": {
      "name": "Qwen3-1.7B-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-1.7B-GGUF/Qwen3-1.7B-Q4_K_S.gguf",
      "filename": "Qwen3-1.7B-Q4_K_S.gguf",
      "format": "gguf",
      "size": 1060190784,
      "sizeGB": "0.99",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.806Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.806Z"
    },
    "Qwen3-1.7B-Q8_0": {
      "name": "Qwen3-1.7B-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-1.7B-Q8_0-GGUF/Qwen3-1.7B-Q8_0.gguf",
      "filename": "Qwen3-1.7B-Q8_0.gguf",
      "format": "gguf",
      "size": 1834426016,
      "sizeGB": "1.71",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.808Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.808Z"
    },
    "Qwen3-14B-Q4_K_S": {
      "name": "Qwen3-14B-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-14B-GGUF/Qwen3-14B-Q4_K_S.gguf",
      "filename": "Qwen3-14B-Q4_K_S.gguf",
      "format": "gguf",
      "size": 8573476224,
      "sizeGB": "7.98",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.809Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.809Z"
    },
    "Qwen3-4B-Thinking-2507-Q4_K_S": {
      "name": "Qwen3-4B-Thinking-2507-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-4B-Thinking-2507-Q4_K_S-GGUF/Qwen3-4B-Thinking-2507-Q4_K_S.gguf",
      "filename": "Qwen3-4B-Thinking-2507-Q4_K_S.gguf",
      "format": "gguf",
      "size": 2383309952,
      "sizeGB": "2.22",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.810Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.811Z"
    },
    "Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S": {
      "name": "Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S-gguf/Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S.gguf",
      "filename": "Qwen3-Coder-30B-A3B-Instruct-128x1.8B-Q2_K_S.gguf",
      "format": "gguf",
      "size": 10740661760,
      "sizeGB": "10.00",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.812Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.812Z"
    },
    "Qwen3-Coder-30B-A3B-Instruct-Q4_K_S": {
      "name": "Qwen3-Coder-30B-A3B-Instruct-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-Coder-30B-A3B-Instruct-Q4_K_S-GGUF/Qwen3-Coder-30B-A3B-Instruct-Q4_K_S.gguf",
      "filename": "Qwen3-Coder-30B-A3B-Instruct-Q4_K_S.gguf",
      "format": "gguf",
      "size": 17456012448,
      "sizeGB": "16.26",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.813Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.813Z"
    },
    "Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1": {
      "name": "Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1-gguf/Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1.gguf",
      "filename": "Qwen3-Esper3-Reasoning-CODER-Instruct-12B-Brainstorm20x.i1-Q4_1.gguf",
      "format": "gguf",
      "size": 7539550848,
      "sizeGB": "7.02",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.814Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.815Z"
    },
    "Qwen3-VL-2B-Thinking-1M-Q4_K_S": {
      "name": "Qwen3-VL-2B-Thinking-1M-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-VL-2B-Thinking-1M-GGUF/Qwen3-VL-2B-Thinking-1M-Q4_K_S.gguf",
      "filename": "Qwen3-VL-2B-Thinking-1M-Q4_K_S.gguf",
      "format": "gguf",
      "size": 1060192576,
      "sizeGB": "0.99",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.816Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.816Z"
    },
    "Qwen3-VL-8B-Thinking-Q4_K_S": {
      "name": "Qwen3-VL-8B-Thinking-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-VL-8B-Thinking-GGUF/Qwen3-VL-8B-Thinking-Q4_K_S.gguf",
      "filename": "Qwen3-VL-8B-Thinking-Q4_K_S.gguf",
      "format": "gguf",
      "size": 4802014496,
      "sizeGB": "4.47",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.818Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.818Z"
    },
    "Qwen3-VL-8B-Thinking.Q4_K": {
      "name": "Qwen3-VL-8B-Thinking.Q4_K",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Qwen3-VL-8B-Thinking.Q4_K-GGUF/Qwen3-VL-8B-Thinking.Q4_K.gguf",
      "filename": "Qwen3-VL-8B-Thinking.Q4_K.gguf",
      "format": "gguf",
      "size": 4608376544,
      "sizeGB": "4.29",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.819Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.820Z"
    },
    "Seed-Coder-8B-Reasoning-UD-Q5_K_XL": {
      "name": "Seed-Coder-8B-Reasoning-UD-Q5_K_XL",
      "path": "/media/bamer/crucial MX300/llm/llama/models/Seed-Coder-8B-Reasoning-GGUF/Seed-Coder-8B-Reasoning-UD-Q5_K_XL.gguf",
      "filename": "Seed-Coder-8B-Reasoning-UD-Q5_K_XL.gguf",
      "format": "gguf",
      "size": 5888349504,
      "sizeGB": "5.48",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.821Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.821Z"
    },
    "fluentlyqwen3-coder-4b-q8_0": {
      "name": "fluentlyqwen3-coder-4b-q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/fluentlyqwen3-coder-4b-q8_0-gguf/fluentlyqwen3-coder-4b-q8_0.gguf",
      "filename": "fluentlyqwen3-coder-4b-q8_0.gguf",
      "format": "gguf",
      "size": 4280401376,
      "sizeGB": "3.99",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.823Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.823Z"
    },
    "gemma-3-1b-it-Q4_K_M": {
      "name": "gemma-3-1b-it-Q4_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/gemma-3-1b-it-Q4_K_M-gguf/gemma-3-1b-it-Q4_K_M.gguf",
      "filename": "gemma-3-1b-it-Q4_K_M.gguf",
      "format": "gguf",
      "size": 806058240,
      "sizeGB": "0.75",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.824Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.824Z"
    },
    "granite-4.0-h-1b-Q4_K_S": {
      "name": "granite-4.0-h-1b-Q4_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4.0-h-1b-GGUF/granite-4.0-h-1b-Q4_K_S.gguf",
      "filename": "granite-4.0-h-1b-Q4_K_S.gguf",
      "format": "gguf",
      "size": 872642112,
      "sizeGB": "0.81",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.826Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.826Z"
    },
    "granite-4.0-h-1b-Q8_0": {
      "name": "granite-4.0-h-1b-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4.0-h-1b-GGUF/granite-4.0-h-1b-Q8_0.gguf",
      "filename": "granite-4.0-h-1b-Q8_0.gguf",
      "format": "gguf",
      "size": 1558926912,
      "sizeGB": "1.45",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.827Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.827Z"
    },
    "granite-4.0-h-350m-Q8_0": {
      "name": "granite-4.0-h-350m-Q8_0",
      "path": "/media/bamer/crucial MX300/llm/llama/models/granite-4.0-h-350m-GGUF/granite-4.0-h-350m-Q8_0.gguf",
      "filename": "granite-4.0-h-350m-Q8_0.gguf",
      "format": "gguf",
      "size": 366196000,
      "sizeGB": "0.34",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.828Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.829Z"
    },
    "magnus-coder.Q4_K_M": {
      "name": "magnus-coder.Q4_K_M",
      "path": "/media/bamer/crucial MX300/llm/llama/models/magnus-coder.Q4_K_M.gguf/magnus-coder.Q4_K_M.gguf",
      "filename": "magnus-coder.Q4_K_M.gguf",
      "format": "gguf",
      "size": 4683084294,
      "sizeGB": "4.36",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.831Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.832Z"
    },
    "miromind-ai_MiroThinker-v1.0-8B-Q6_K_L": {
      "name": "miromind-ai_MiroThinker-v1.0-8B-Q6_K_L",
      "path": "/media/bamer/crucial MX300/llm/llama/models/miromind-ai_MiroThinker-v1.0-8B-Q6_K_L-gguf/miromind-ai_MiroThinker-v1.0-8B-Q6_K_L.gguf",
      "filename": "miromind-ai_MiroThinker-v1.0-8B-Q6_K_L.gguf",
      "format": "gguf",
      "size": 7027341312,
      "sizeGB": "6.54",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.833Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.833Z"
    },
    "neutss-air-BF16": {
      "name": "neutss-air-BF16",
      "path": "/media/bamer/crucial MX300/llm/llama/models/neutts-air/neutss-air-BF16.gguf",
      "filename": "neutss-air-BF16.gguf",
      "format": "gguf",
      "size": 1503776000,
      "sizeGB": "1.40",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.834Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.835Z"
    },
    "nvidia-nemotron-nano-9b-v2-q4_k_m": {
      "name": "nvidia-nemotron-nano-9b-v2-q4_k_m",
      "path": "/media/bamer/crucial MX300/llm/llama/models/nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S-gguf/nvidia-nemotron-nano-9b-v2-q4_k_m.gguf",
      "filename": "nvidia-nemotron-nano-9b-v2-q4_k_m.gguf",
      "format": "gguf",
      "size": 6525629280,
      "sizeGB": "6.08",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.836Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.837Z"
    },
    "nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S": {
      "name": "nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S",
      "path": "/media/bamer/crucial MX300/llm/llama/models/nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S-gguf/nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S.gguf",
      "filename": "nvidia_NVIDIA-Nemotron-Nano-12B-v2-Q5_K_S.gguf",
      "format": "gguf",
      "size": 8567895552,
      "sizeGB": "7.98",
      "status": "ready",
      "discovered_at": "2025-12-03T19:19:34.838Z",
      "ctx_size": 4096,
      "batch_size": 2048,
      "ubatch_size": 512,
      "models_dir": "",
      "multimodal_enabled": false,
      "mmproj_path": "",
      "enable_vision": false,
      "enable_audio": false,
      "image_batch_size": 512,
      "audio_batch_size": 512,
      "temp": 0.7,
      "top_k": 40,
      "top_p": 0.9,
      "min_p": 0,
      "repeat_penalty": 1.1,
      "presence_penalty": 0,
      "frequency_penalty": 0,
      "mirostat": 0,
      "mirostat_tau": 5,
      "mirostat_eta": 0.1,
      "ts_enabled": false,
      "ts_rows": "22,78",
      "ts_base": 10000,
      "cache_reuse": 0,
      "threads": 8,
      "thread_batch": 512,
      "gpu_layers": 35,
      "main_gpu": 0,
      "tensor_split": [],
      "parallel": 1,
      "n_cpu_moe": 0,
      "mlock": false,
      "mmap": true,
      "no_mmap": false,
      "numa": false,
      "flash_attn": false,
      "no_kv_offload": false,
      "simple_io": false,
      "kv_unified": false,
      "no_warmup": false,
      "use_mmap": true,
      "use_mlock": false,
      "cpu_moe": false,
      "host": "127.0.0.1",
      "port": 8000,
      "n_parallel": 1,
      "n_sequences": 1,
      "timeout": 600000,
      "jinja": false,
      "alias": "",
      "log_all": false,
      "verbose": false,
      "log_colors": false,
      "cuda_device": "",
      "ggml_cuda_enable_unified_memory": false,
      "numa_affinity": false,
      "saved_at": "2025-12-03T19:19:34.839Z"
    }
  },
  "paths": {
    "modelsDirectory": "/media/bamer/crucial MX300/llm/llama/models"
  },
  "proxies": {
    "lmstudio": {
      "enabled": true
    },
    "ollama": {
      "enabled": true
    }
  },
  "monitoring": {
    "enableGpuMonitoring": true,
    "enableDetailedLogging": true
  }
}