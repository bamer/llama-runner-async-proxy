{
  "id": "Qwen2.5-Vl-7B-Instruct",
  "object": "model",
  "type": "llm",
  "publisher": "Unsloth",
  "arch": "qwen2vl",
  "compatibility_type": "gguf",
  "quantization": "Q4_K_S",
  "max_context_length": 128000,
  "raw_metadata": {
    "GGUF.version": 3,
    "GGUF.tensor_count": 339,
    "GGUF.kv_count": 32,
    "general.architecture": "qwen2vl",
    "general.type": "model",
    "general.name": "Qwen2.5-Vl-7B-Instruct",
    "general.finetune": "Instruct",
    "general.basename": "Qwen2.5-Vl-7B-Instruct",
    "general.quantized_by": "Unsloth",
    "general.size_label": "7B",
    "general.repo_url": "https://huggingface.co/unsloth",
    "qwen2vl.block_count": 28,
    "qwen2vl.context_length": 128000,
    "qwen2vl.embedding_length": 3584,
    "qwen2vl.feed_forward_length": 18944,
    "qwen2vl.attention.head_count": 28,
    "qwen2vl.attention.head_count_kv": 4,
    "qwen2vl.rope.freq_base": 1000000.0,
    "qwen2vl.attention.layer_norm_rms_epsilon": 9.999999974752427e-07,
    "qwen2vl.rope.dimension_sections": 16,
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "qwen2",
    "tokenizer.ggml.tokens": 33,
    "tokenizer.ggml.token_type": 1,
    "tokenizer.ggml.merges": "\u0120 \u0120",
    "tokenizer.ggml.eos_token_id": 151645,
    "tokenizer.ggml.padding_token_id": 151654,
    "tokenizer.ggml.add_bos_token": false,
    "tokenizer.chat_template": "{% set image_count = namespace(value=0) %}{% set video_count = namespace(value=0) %}{% for message in messages %}{% if loop.first and message['role'] != 'system' %}<|im_start|>system\nYou are a helpful assistant.<|im_end|>\n{% endif %}<|im_start|>{{ message['role'] }}\n{% if message['content'] is string %}{{ message['content'] }}<|im_end|>\n{% else %}{% for content in message['content'] %}{% if content['type'] == 'image' or 'image' in content or 'image_url' in content %}{% set image_count.value = image_count.value + 1 %}{% if add_vision_id %}Picture {{ image_count.value }}: {% endif %}<|vision_start|><|image_pad|><|vision_end|>{% elif content['type'] == 'video' or 'video' in content %}{% set video_count.value = video_count.value + 1 %}{% if add_vision_id %}Video {{ video_count.value }}: {% endif %}<|vision_start|><|video_pad|><|vision_end|>{% elif 'text' in content %}{{ content['text'] }}{% endif %}{% endfor %}<|im_end|>\n{% endif %}{% endfor %}{% if add_generation_prompt %}<|im_start|>assistant\n{% endif %}",
    "general.quantization_version": 2,
    "general.file_type": 14,
    "quantize.imatrix.file": "Qwen2.5-VL-7B-Instruct-GGUF/imatrix_unsloth.dat",
    "quantize.imatrix.dataset": "unsloth_calibration_Qwen2.5-VL-7B-Instruct.txt",
    "quantize.imatrix.entries_count": 196,
    "quantize.imatrix.chunks_count": 691
  },
  "state": "not-loaded",
  "size": 4457767808
}