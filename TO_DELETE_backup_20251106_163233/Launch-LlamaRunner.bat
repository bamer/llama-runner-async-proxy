@echo off
REM ===============================================================================
REM ğŸš€ LlamaRunner Pro - Lanceur Principal (Batch)
REM Created by Bamer - Professional AI Proxy Suite Launcher
REM ===============================================================================

setlocal enabledelayedexpansion

echo.
echo â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
echo â•‘                    ğŸš€ LlamaRunner Pro                        â•‘
echo â•‘                  Professional AI Proxy Suite                  â•‘
echo â•‘                        by Bamer                                â•‘
echo â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo.

REM DÃ©tecter le rÃ©pertoire du script
set "SCRIPT_DIR=%~dp0"
set "SCRIPT_DIR=%SCRIPT_DIR:~0,-1%"
cd /d "%SCRIPT_DIR%"

REM Chemins des fichiers
set "VENV_PATH=%SCRIPT_DIR%\dev-venv"
set "PYTHON_PATH=%VENV_PATH%\Scripts\python.exe"
set "MAIN_SCRIPT=%SCRIPT_DIR%\main.py"
set "METRICS_SCRIPT=%SCRIPT_DIR%\llama_runner\metrics_server.py"
set "TEST_SCRIPT=%SCRIPT_DIR%\test_implementation_validation.py"
set "POWERSHELL_SCRIPT=%SCRIPT_DIR%\Launch-LlamaRunner.ps1"

REM Traiter les arguments
if "%1"=="-h" goto :show_help
if "%1"=="--help" goto :show_help
if "%1"=="/h" goto :show_help
if "%1"=="/?" goto :show_help

if "%1"=="-install" goto :install_deps
if "%1"=="--install" goto :install_deps

if "%1"=="-test" goto :run_tests
if "%1"=="--test" goto :run_tests

if "%1"=="-proxy" goto :start_proxy
if "%1"=="--proxy" goto :start_proxy

if "%1"=="-webui" goto :start_webui
if "%1"=="--webui" goto :start_webui

if "%1"=="-metrics" goto :start_metrics
if "%1"=="--metrics" goto :start_metrics

if "%1"=="-dev" goto :start_dev
if "%1"=="--dev" goto :start_dev

if "%1"=="-headless" goto :start_headless
if "%1"=="--headless" goto :start_headless

REM Si PowerShell est disponible, dÃ©lÃ©guer au script PowerShell
where powershell >nul 2>&1
if !errorlevel! equ 0 (
    echo ğŸ”„ Redirection vers PowerShell pour l'interface interactive...
    powershell -ExecutionPolicy Bypass -File "%POWERSHELL_SCRIPT%" %*
    goto :end
)

REM Sinon, mode menu simple
goto :interactive_menu

:show_help
echo ğŸ¯ MODES DE LANCEMENT DISPONIBLES:
echo.
echo Options principales:
echo   -install         : Installation des dÃ©pendances Python
echo   -proxy           : Lance le proxy (LM Studio + Ollama)
echo   -webui           : Lance le proxy + interface web
echo   -metrics         : Lance proxy + web UI + dashboard mÃ©triques
echo   -dev             : Mode dÃ©veloppement avec logs dÃ©taillÃ©s
echo   -headless        : Mode serveur sans interface graphique
echo   -test            : Lance les tests de validation
echo   -h, --help       : Affiche cette aide
echo.
echo Exemples d'utilisation:
echo   Launch-LlamaRunner.bat -install
echo   Launch-LlamaRunner.bat -proxy
echo   Launch-LlamaRunner.bat -metrics
echo   Launch-LlamaRunner.bat -test
echo.
echo ğŸ’¡ Pour l'interface interactive complÃ¨te, utilisez PowerShell:
echo   powershell -ExecutionPolicy Bypass -File Launch-LlamaRunner.ps1
goto :end

:install_deps
echo ğŸ“¦ INSTALLATION DES DÃ‰PENDANCES
echo.

REM CrÃ©er l'environnement virtuel s'il n'existe pas
if not exist "%VENV_PATH%" (
    echo ğŸ—ï¸  CrÃ©ation de l'environnement virtuel...
    python -m venv "%VENV_PATH%"
    if !errorlevel! neq 0 (
        echo âŒ Ã‰chec de crÃ©ation de l'environnement virtuel
        goto :end
    )
)

REM Mettre Ã  jour pip
echo ğŸ“ˆ Mise Ã  jour de pip...
"%PYTHON_PATH%" -m pip install --upgrade pip

REM Installer les dÃ©pendances
echo ğŸ“š Installation des dÃ©pendances...
"%PYTHON_PATH%" -m pip install -r requirements.txt

if !errorlevel! equ 0 (
    echo âœ… Installation terminÃ©e avec succÃ¨s!
) else (
    echo âŒ Ã‰chec de l'installation des dÃ©pendances
)
goto :end

:run_tests
echo ğŸ§ª LANCEMENT DES TESTS DE VALIDATION
echo.

if not exist "%PYTHON_PATH%" (
    echo âŒ Python non trouvÃ©. ExÃ©cutez d'abord: Launch-LlamaRunner.bat -install
    goto :end
)

"%PYTHON_PATH%" "%TEST_SCRIPT%"
goto :end

:start_proxy
echo ğŸš€ DÃ‰MARRAGE DU PROXY LLAMARUNNER
echo.

if not exist "%PYTHON_PATH%" (
    echo âŒ Python non trouvÃ©. ExÃ©cutez d'abord: Launch-LlamaRunner.bat -install
    goto :end
)

echo ğŸ“¡ LM Studio: http://localhost:1234
echo ğŸ¦™ Ollama: http://localhost:11434
echo.
echo âœ… Proxy dÃ©marrÃ©! Appuyez sur Ctrl+C pour arrÃªter
echo.

"%PYTHON_PATH%" "%MAIN_SCRIPT%" --config config.json --log-level INFO --lm-studio-port 1234 --ollama-port 11434
goto :end

:start_webui
echo ğŸŒ DÃ‰MARRAGE DU PROXY + INTERFACE WEB
echo.

if not exist "%PYTHON_PATH%" (
    echo âŒ Python non trouvÃ©. ExÃ©cutez d'abord: Launch-LlamaRunner.bat -install
    goto :end
)

echo ğŸ“¡ LM Studio: http://localhost:1234
echo ğŸ¦™ Ollama: http://localhost:11434
echo ğŸŒ Interface Web: http://localhost:3000
echo.
echo âœ… Proxy dÃ©marrÃ©! Ouvrez votre navigateur sur http://localhost:3000
echo.

"%PYTHON_PATH%" "%MAIN_SCRIPT%" --config config.json --log-level INFO --lm-studio-port 1234 --ollama-port 11434 --web-ui
goto :end

:start_metrics
echo ğŸ“Š DÃ‰MARRAGE DU SYSTÃˆME COMPLET (PROXY + WEB UI + MÃ‰TRIQUES)
echo.

if not exist "%PYTHON_PATH%" (
    echo âŒ Python non trouvÃ©. ExÃ©cutez d'abord: Launch-LlamaRunner.bat -install
    goto :end
)

echo ğŸ“Š Dashboard MÃ©triques: http://localhost:8585
echo ğŸŒ Interface Web: http://localhost:3000
echo ğŸ“¡ LM Studio: http://localhost:1234
echo ğŸ¦™ Ollama: http://localhost:11434
echo.
echo âœ… SystÃ¨me complet dÃ©marrÃ©! 
echo.
echo ğŸ“Š Ouvrez votre navigateur sur:
echo    - Dashboard: http://localhost:8585
echo    - Interface: http://localhost:3000
echo.
echo Appuyez sur Ctrl+C pour arrÃªter tous les services
echo.

start "Dashboard MÃ©triques" cmd /c "echo DÃ©marrage du serveur de mÃ©triques... && timeout /t 3 && start http://localhost:8585"
timeout /t 2 >nul

"%PYTHON_PATH%" "%METRICS_SCRIPT%" &
set METRICS_PID=!errorlevel!

timeout /t 2 >nul
"%PYTHON_PATH%" "%MAIN_SCRIPT%" --config config.json --log-level INFO --lm-studio-port 1234 --ollama-port 11434 --web-ui --metrics-port 8585

REM ArrÃªter le serveur de mÃ©triques
if defined METRICS_PID taskkill /PID !METRICS_PID! /F >nul 2>&1
goto :end

:start_dev
echo ğŸ”§ DÃ‰MARRAGE EN MODE DÃ‰VELOPPEMENT
echo.

if not exist "%PYTHON_PATH%" (
    echo âŒ Python non trouvÃ©. ExÃ©cutez d'abord: Launch-LlamaRunner.bat -install
    goto :end
)

echo ğŸ“ Logs dÃ©taillÃ©s activÃ©s
echo ğŸ“¡ LM Studio: http://localhost:1234
echo ğŸ¦™ Ollama: http://localhost:11434
echo.
echo âœ… Mode dÃ©veloppement dÃ©marrÃ©!
echo.

"%PYTHON_PATH%" "%MAIN_SCRIPT%" --config config.json --log-level DEBUG --lm-studio-port 1234 --ollama-port 11434
goto :end

:start_headless
echo ğŸ–¥ï¸  DÃ‰MARRAGE EN MODE HEADLESS
echo.

if not exist "%PYTHON_PATH%" (
    echo âŒ Python non trouvÃ©. ExÃ©cutez d'abord: Launch-LlamaRunner.bat -install
    goto :end
)

echo ğŸ“¡ LM Studio: http://localhost:1234
echo ğŸ¦™ Ollama: http://localhost:11434
echo.
echo âœ… Mode headless dÃ©marrÃ©!
echo.

"%PYTHON_PATH%" "%MAIN_SCRIPT%" --config config.json --log-level INFO --lm-studio-port 1234 --ollama-port 11434 --headless
goto :end

:interactive_menu
echo ğŸ¯ SÃ‰LECTIONNEZ LE MODE DE LANCEMENT:
echo.
echo 1. ğŸƒâ€â™‚ï¸ Proxy uniquement (LM Studio + Ollama)
echo 2. ğŸŒ Proxy + Interface Web
echo 3. ğŸ“Š Proxy + Web UI + Dashboard MÃ©triques (Complet)
echo 4. ğŸ”§ Mode DÃ©veloppement (avec logs dÃ©taillÃ©s)
echo 5. ğŸ–¥ï¸  Mode Headless (serveur sans GUI)
echo 6. ğŸ§ª Lancer les tests de validation
echo 7. ğŸ“¦ Installer/Mise Ã  jour des dÃ©pendances
echo 8. âŒ Quitter
echo.

:menu_choice
set /p choice="ğŸ‘‰ Votre choix (1-8): "

if "%choice%"=="1" goto :start_proxy
if "%choice%"=="2" goto :start_webui
if "%choice%"=="3" goto :start_metrics
if "%choice%"=="4" goto :start_dev
if "%choice%"=="5" goto :start_headless
if "%choice%"=="6" goto :run_tests
if "%choice%"=="7" goto :install_deps
if "%choice%"=="8" goto :end

echo âŒ Choix invalide. Veuillez choisir un numÃ©ro entre 1 et 8.
goto :menu_choice

:end
echo.
echo ğŸ‘‹ Merci d'avoir utilisÃ© LlamaRunner Pro!
echo ğŸ’¡ Pour plus d'options, utilisez: Launch-LlamaRunner.bat --help
echo.
pause
