# ğŸ¦™ LlamaRunner Pro - Async Proxy System

**Version Phase 2 - Structure stabilisÃ©e et corrigÃ©e**

## ğŸ¯ PrÃ©sentation

LlamaRunner Pro est un systÃ¨me proxy asynchrone unifiÃ© qui sert d'interface entre diffÃ©rents modÃ¨les d'IA (LM Studio, Ollama, etc.) avec un tableau de bord web Vue.js pour le monitoring en temps rÃ©el. Le systÃ¨me est conÃ§u pour Ãªtre autonome, modulaire et fonctionner sur Windows/Linux.

## ğŸ›  Stack Technique

### Backend Python
- **Python 3.11+** avec FastAPI/uvicorn pour l'API asynchrone
- **WebSocket** pour la communication temps rÃ©el
- **psutil** pour la collecte de mÃ©triques systÃ¨me (CPU, mÃ©moire, GPU)
- **PyInstaller** pour la gÃ©nÃ©ration d'exÃ©cutables
- **PySide6** pour une interface desktop optionnelle

### Frontend Vue.js
- **Vue.js 3** + **Element Plus** pour l'UI
- **Chart.js** pour la visualisation des donnÃ©es en temps rÃ©el
- **Vite** pour le build et SCSS pour le style

### Outils de dÃ©veloppement
- **PowerShell 7+** comme interface principale (`LaunchMenu.ps1`)
- **VS Code** comme IDE recommandÃ©
- **pytest**/**unittest** pour les tests
- **Virtualenv**/**Anaconda** pour l'environnement (pas de Docker)

## ğŸ“ Structure du Projet (Phase 2)

```
llama-runner-async-proxy/
â”œâ”€â”€ LaunchMenu.ps1               # Menu interactif principal
â”œâ”€â”€ main.py                      # Point d'entrÃ©e Python
â”œâ”€â”€ config/                      # Fichiers de configuration
â”‚   â”œâ”€â”€ config.json              # Configuration gÃ©nÃ©rale
â”‚   â”œâ”€â”€ models.json              # ParamÃ¨tres spÃ©cifiques aux modÃ¨les
â”‚   â””â”€â”€ ports.json               # Mapping des ports rÃ©seau et API
â”œâ”€â”€ logs/                        # Logs tournants
â”œâ”€â”€ scripts/                     # Outils PowerShell
â”‚   â”œâ”€â”€ model_management.ps1    # Gestion des modÃ¨les (.gguf)
â”‚   â”œâ”€â”€ validate_system.ps1      # Validation systÃ¨me
â”‚   â”œâ”€â”€ port_config.ps1          # Configuration rÃ©seau
â”‚   â””â”€â”€ debug_launch.ps1         # Mode debug
â”œâ”€â”€ tests/                       # Tests unitaires et d'intÃ©gration
â”‚   â”œâ”€â”€ unit/                    # Tests unitaires
â”‚   â””â”€â”€ integration/             # Tests d'intÃ©gration
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ README.md                # Ce fichier
â”‚   â”œâ”€â”€ INSTALLATION.md          # Instructions d'installation
â”‚   â””â”€â”€ USAGE.md                 # Mode d'emploi
â”œâ”€â”€ dashboard/                   # Frontend Vue.js + Chart.js
â”œâ”€â”€ llama_runner/                # Backend Python central
â”‚   â”œâ”€â”€ main.py                  # Serveur FastAPI principal
â”‚   â”œâ”€â”€ proxy_manager.py         # Gestion centralisÃ©e des proxies
â”‚   â”œâ”€â”€ config_loader.py         # Chargement et validation de configuration
â”‚   â”œâ”€â”€ runner_manager.py        # Gestion des services de runner
â”‚   â””â”€â”€ services/                # Services spÃ©cialisÃ©s
â”‚       â”œâ”€â”€ config_updater.py    # Mise Ã  jour de configuration
â”‚       â”œâ”€â”€ config_validator.py  # Validation de configuration
â”‚       â””â”€â”€ metrics_collector.py # Collecte de mÃ©triques
â”œâ”€â”€ models/                      # ModÃ¨les GGUF tÃ©lÃ©chargÃ©s
â”œâ”€â”€ tools/                       # Outils externes (llama-server.exe, etc.)
â””â”€â”€ requirements.txt             # DÃ©pendances Python
```

## ğŸš€ DÃ©marrage Rapide

### 1. Configuration de l'environnement

```powershell
# CrÃ©er un environnement virtuel
python -m venv dev-venv

# Activer l'environnement
.\dev-venv\Scripts\Activate.ps1

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 2. Lancer le menu interactif

```powershell
.\LaunchMenu.ps1
```

### 3. Choisir un mode de fonctionnement

- **ğŸš€ Mode Proxy (Serveur principal)** : Proxy asynchrone pour tous les modÃ¨les
- **ğŸ¦™ Mode Llama.cpp seul** : Uniquement le serveur llama.cpp
- **ğŸŒ Mode Proxy + WebUI** : Proxy avec interface web
- **ğŸ“Š Mode Proxy + WebUI + Dashboard** : Proxy avec monitoring temps rÃ©el
- **ğŸ”§ Mode DÃ©veloppement (Debug)** : Logs dÃ©taillÃ©s et debugging
- **ğŸ§ª Tests du systÃ¨me** : ExÃ©cuter la suite de tests

## ğŸ” Validation du SystÃ¨me

Avant de dÃ©marrer, validez votre configuration :

```powershell
.\scripts\validate_system.ps1
```

Ce script vÃ©rifie :
- âœ… DisponibilitÃ© des ports (1234, 11434, 8035)
- âœ… Environnement Python et dÃ©pendances
- âœ… Structure du projet
- âœ… Configuration des modÃ¨les

## ğŸ§ª Tests AutomatisÃ©s

ExÃ©cutez les tests unitaires :

```powershell
pytest tests/
```

## ğŸ“ Documentation ComplÃ¨te

- **[INSTALLATION.md](INSTALLATION.md)** : Instructions d'installation dÃ©taillÃ©es
- **[USAGE.md](USAGE.md)** : Guide d'utilisation complet
- **[CONTRIBUTING.md](CONTRIBUTING.md)** : Guide pour les contributeurs

## ğŸ” SÃ©curitÃ© et Configuration

- **Ports standards** :
  - LM Studio API : **1234**
  - Ollama API : **11434**
  - Dashboard Web : **8035**

- **Permissions** : Les fichiers sensibles ont des permissions restreintes
- **DÃ©ploiement** : Local uniquement, avec venv ou Anaconda, pas de Docker

## ğŸ¤ Contribution

Nous suivons des principes stricts pour les contributeurs :

- **SÃ©curitÃ©** : Ne jamais supprimer de fichiers sans analyse prÃ©alable
- **QualitÃ©** : Commits atomiques et significatifs
- **Tests** : Jamais ignorer les diagnostics de haute sÃ©vÃ©ritÃ©
- **Documentation** : Documenter chaque changement fonctionnel
- **Typage** : Suivre Ã  100% les conventions de typage et de nommage
- **Validation** : ExÃ©cuter tous les tests localement avant de committer

## ğŸ†˜ Support et DÃ©bogage

Si vous rencontrez des problÃ¨mes :

1. **VÃ©rifiez les logs** : `logs/app.log` et `logs/launch_menu.log`
2. **ExÃ©cutez la validation** : `.\scripts\validate_system.ps1`
3. **Mode debug** : Utilisez `.\LaunchMenu.ps1` â†’ "ğŸ”§ Mode DÃ©veloppement"
4. **Issues GitHub** : CrÃ©ez une issue avec les logs et Ã©tapes de reproduction

## ğŸ“œ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](../LICENSE) pour plus de dÃ©tails.

---

**Projet stabilisÃ© en Phase 2** âœ…  
Structure corrigÃ©e, chemins relatifs, imports fixÃ©s, documentation minimale crÃ©Ã©e.