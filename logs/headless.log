2025-11-11 14:49:50,531 - INFO - root - Logging configured for headless mode
2025-11-11 14:49:50,531 - INFO - root - === STARTING HEADLESS SERVICE ===
2025-11-11 14:49:50,532 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 14:49:50,532 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 14:49:50,532 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 14:49:50,532 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 14:49:50,533 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 14:49:50,533 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 14:49:50,533 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 14:49:50,533 - WARNING - llama_runner.services.config_validator - [WARNING] config: No models configured
2025-11-11 14:49:50,533 - WARNING - llama_runner.services.config_validator - Configuration validation passed with 1 warning(s)
2025-11-11 14:49:50,534 - INFO - root - Configuration loaded and validated successfully
2025-11-11 14:49:50,534 - INFO - llama_runner.headless_service_manager - Initializing services for headless mode...
2025-11-11 14:49:50,534 - WARNING - llama_runner.headless_service_manager - Audio section is missing or None in config. Using empty models dict.
2025-11-11 14:49:50,534 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 14:49:50,534 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 14:49:50,534 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 14:49:50,534 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 14:49:50,535 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 14:49:50,535 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 14:49:50,535 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 14:49:50,535 - INFO - llama_runner.headless_service_manager - LlamaRunnerManager initialized.
2025-11-11 14:49:50,536 - INFO - llama_runner.headless_service_manager - Ollama Proxy is enabled. Creating server...
2025-11-11 14:49:50,536 - INFO - llama_runner.headless_service_manager - LM Studio Proxy is enabled. Creating server...
2025-11-11 14:49:50,537 - DEBUG - asyncio - Using proactor: IocpProactor
2025-11-11 14:49:50,538 - INFO - root - 
============================================================
2025-11-11 14:49:50,538 - INFO - root - SERVICES ACCESSIBLES :
2025-11-11 14:49:50,538 - INFO - root - ============================================================
2025-11-11 14:49:50,538 - INFO - root - Ollama Proxy: http://127.0.0.1:11434/
2025-11-11 14:49:50,538 - INFO - root - LM Studio Proxy: http://127.0.0.1:1234/
2025-11-11 14:49:50,538 - INFO - root - Dashboard Web: http://127.0.0.1:8035/
2025-11-11 14:49:50,538 - INFO - root - Metrics Server: http://127.0.0.1:8080/
2025-11-11 14:49:50,538 - INFO - root - ============================================================

2025-11-11 14:49:50,539 - INFO - root - Starting all services...
2025-11-11 14:49:50,539 - CRITICAL - root - Critical error in headless service: no running event loop
Traceback (most recent call last):
  File "F:\llm\llama-runner-async-proxy\main.py", line 193, in main
    asyncio.create_task(hsm.start_services())
  File "C:\Users\theba\.pyenv\pyenv-win\versions\3.12.4\Lib\asyncio\tasks.py", line 417, in create_task
    loop = events.get_running_loop()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: no running event loop
2025-11-11 14:49:50,540 - INFO - root - Headless service shutting down
2025-11-11 14:57:10,349 - INFO - root - Logging configured for headless mode
2025-11-11 14:57:10,349 - INFO - root - === STARTING HEADLESS SERVICE ===
2025-11-11 14:57:10,349 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 14:57:10,349 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 14:57:10,350 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 14:57:10,350 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 14:57:10,350 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 14:57:10,350 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 14:57:10,350 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 14:57:10,351 - WARNING - llama_runner.services.config_validator - [WARNING] config: No models configured
2025-11-11 14:57:10,351 - WARNING - llama_runner.services.config_validator - Configuration validation passed with 1 warning(s)
2025-11-11 14:57:10,351 - INFO - root - Configuration loaded and validated successfully
2025-11-11 14:57:10,351 - INFO - llama_runner.headless_service_manager - Initializing services for headless mode...
2025-11-11 14:57:10,351 - WARNING - llama_runner.headless_service_manager - Audio section is missing or None in config. Using empty models dict.
2025-11-11 14:57:10,351 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 14:57:10,351 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 14:57:10,352 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 14:57:10,352 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 14:57:10,352 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 14:57:10,352 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 14:57:10,352 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 14:57:10,353 - INFO - llama_runner.headless_service_manager - LlamaRunnerManager initialized.
2025-11-11 14:57:10,353 - INFO - llama_runner.headless_service_manager - Ollama Proxy is enabled. Creating server...
2025-11-11 14:57:10,353 - INFO - llama_runner.headless_service_manager - LM Studio Proxy is enabled. Creating server...
2025-11-11 14:57:10,353 - DEBUG - asyncio - Using proactor: IocpProactor
2025-11-11 14:57:10,354 - INFO - root - 
============================================================
2025-11-11 14:57:10,354 - INFO - root - SERVICES ACCESSIBLES :
2025-11-11 14:57:10,354 - INFO - root - ============================================================
2025-11-11 14:57:10,355 - INFO - root - Ollama Proxy: http://127.0.0.1:11434/
2025-11-11 14:57:10,355 - INFO - root - LM Studio Proxy: http://127.0.0.1:1234/
2025-11-11 14:57:10,355 - INFO - root - Dashboard Web: http://127.0.0.1:8035/
2025-11-11 14:57:10,355 - INFO - root - Metrics Server: http://127.0.0.1:8080/
2025-11-11 14:57:10,355 - INFO - root - ============================================================

2025-11-11 14:57:10,355 - INFO - root - Starting all services...
2025-11-11 14:57:10,355 - INFO - root - Headless service running. Press Ctrl+C to shutdown.
2025-11-11 14:57:10,356 - INFO - llama_runner.headless_service_manager - Starting all services...
2025-11-11 14:57:10,356 - INFO - llama_runner.headless_service_manager - Starting Ollama proxy server...
2025-11-11 14:57:10,356 - INFO - llama_runner.headless_service_manager - ‚úÖ Ollama Proxy server started on http://0.0.0.0:11434/
2025-11-11 14:57:10,357 - INFO - llama_runner.headless_service_manager - Starting LM Studio proxy server...
2025-11-11 14:57:10,357 - INFO - llama_runner.headless_service_manager - ‚úÖ LM Studio Proxy server started on http://0.0.0.0:1234/
2025-11-11 14:57:10,357 - INFO - llama_runner.headless_service_manager - Starting Llama Runner WebUI service on port 8081...
2025-11-11 14:57:10,358 - INFO - llama_runner.headless_service_manager - ‚úÖ Llama Runner WebUI service started on http://0.0.0.0:8081/
2025-11-11 14:57:10,358 - INFO - llama_runner.headless_service_manager -    üåê Access via: http://localhost:8081/
2025-11-11 14:57:10,358 - INFO - llama_runner.headless_service_manager - ‚úÖ All services started successfully. Waiting for shutdown signal...
2025-11-11 14:57:10,358 - INFO - llama_runner.headless_service_manager - 
============================================================
2025-11-11 14:57:10,359 - INFO - llama_runner.headless_service_manager - üåê SERVICES ACCESSIBLES :
2025-11-11 14:57:10,359 - INFO - llama_runner.headless_service_manager - ============================================================
2025-11-11 14:57:10,359 - INFO - llama_runner.headless_service_manager - üè† llama.cpp WebUI: http://localhost:8035/
2025-11-11 14:57:10,359 - INFO - llama_runner.headless_service_manager -    ‚úÖ Direct access - no proxy needed
2025-11-11 14:57:10,360 - INFO - llama_runner.headless_service_manager - üè† Llama Runner WebUI: http://localhost:8081/
2025-11-11 14:57:10,360 - INFO - llama_runner.headless_service_manager - üîó Ollama Proxy: http://localhost:11434/
2025-11-11 14:57:10,360 - INFO - llama_runner.headless_service_manager - üîó LM Studio Proxy: http://localhost:1234/
2025-11-11 14:57:10,360 - INFO - llama_runner.headless_service_manager - ============================================================

2025-11-11 17:56:21,734 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:21,735 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:21,735 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:21,735 - INFO - llama_runner.headless_service_manager - Stopping Ollama proxy...
2025-11-11 17:56:21,735 - INFO - llama_runner.headless_service_manager - Stopping LM Studio proxy...
2025-11-11 17:56:21,735 - INFO - llama_runner.headless_service_manager - Stopping Llama Runner WebUI...
2025-11-11 17:56:21,844 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:21,844 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:21,844 - INFO - root - All services stopped gracefully
2025-11-11 17:56:40,987 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:40,987 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:40,987 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:40,987 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:40,987 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:40,988 - INFO - root - All services stopped gracefully
2025-11-11 17:56:42,635 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:42,635 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:42,635 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:42,635 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:42,636 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:42,636 - INFO - root - All services stopped gracefully
2025-11-11 17:56:43,027 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:43,028 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:43,028 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:43,028 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:43,028 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:43,028 - INFO - root - All services stopped gracefully
2025-11-11 17:56:43,235 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:43,235 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:43,235 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:43,235 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:43,235 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:43,236 - INFO - root - All services stopped gracefully
2025-11-11 17:56:43,427 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:43,427 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:43,427 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:43,428 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:43,428 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:43,428 - INFO - root - All services stopped gracefully
2025-11-11 17:56:43,658 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:43,659 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:43,659 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:43,659 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:43,659 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:43,660 - INFO - root - All services stopped gracefully
2025-11-11 17:56:43,939 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:43,939 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:43,939 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:43,940 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:43,940 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:43,940 - INFO - root - All services stopped gracefully
2025-11-11 17:56:44,530 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:44,531 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:44,531 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:44,531 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:44,531 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:44,531 - INFO - root - All services stopped gracefully
2025-11-11 17:56:44,731 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 17:56:44,731 - INFO - root - Shutdown requested, stopping services...
2025-11-11 17:56:44,731 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 17:56:44,731 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 17:56:44,732 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 17:56:44,732 - INFO - root - All services stopped gracefully
2025-11-11 18:05:52,479 - INFO - root - Logging configured for headless mode
2025-11-11 18:05:52,479 - INFO - root - === STARTING HEADLESS SERVICE ===
2025-11-11 18:05:52,479 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 18:05:52,479 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 18:05:52,480 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 18:05:52,480 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 18:05:52,480 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 18:05:52,480 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 18:05:52,481 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 18:05:52,481 - WARNING - llama_runner.services.config_validator - [WARNING] config: No models configured
2025-11-11 18:05:52,481 - WARNING - llama_runner.services.config_validator - Configuration validation passed with 1 warning(s)
2025-11-11 18:05:52,481 - INFO - root - Configuration loaded and validated successfully
2025-11-11 18:05:52,481 - INFO - llama_runner.headless_service_manager - Initializing services for headless mode...
2025-11-11 18:05:52,481 - WARNING - llama_runner.headless_service_manager - Audio section is missing or None in config. Using empty models dict.
2025-11-11 18:05:52,482 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 18:05:52,482 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 18:05:52,482 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 18:05:52,482 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 18:05:52,482 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 18:05:52,482 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 18:05:52,482 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 18:05:52,483 - INFO - llama_runner.headless_service_manager - LlamaRunnerManager initialized.
2025-11-11 18:05:52,483 - INFO - llama_runner.headless_service_manager - Ollama Proxy is enabled. Creating server...
2025-11-11 18:05:52,483 - INFO - llama_runner.headless_service_manager - LM Studio Proxy is enabled. Creating server...
2025-11-11 18:05:52,484 - DEBUG - asyncio - Using proactor: IocpProactor
2025-11-11 18:05:52,485 - INFO - root - 
============================================================
2025-11-11 18:05:52,485 - INFO - root - SERVICES ACCESSIBLES :
2025-11-11 18:05:52,485 - INFO - root - ============================================================
2025-11-11 18:05:52,485 - INFO - root - Ollama Proxy: http://127.0.0.1:11434/
2025-11-11 18:05:52,486 - INFO - root - LM Studio Proxy: http://127.0.0.1:1234/
2025-11-11 18:05:52,486 - INFO - root - Dashboard Web: http://127.0.0.1:8035/
2025-11-11 18:05:52,486 - INFO - root - Metrics Server: http://127.0.0.1:8080/
2025-11-11 18:05:52,486 - INFO - root - ============================================================

2025-11-11 18:05:52,486 - INFO - root - Starting all services...
2025-11-11 18:05:52,486 - INFO - root - Headless service running. Press Ctrl+C to shutdown.
2025-11-11 18:05:52,486 - INFO - llama_runner.headless_service_manager - Starting all services...
2025-11-11 18:05:52,486 - INFO - llama_runner.headless_service_manager - Starting Ollama proxy server...
2025-11-11 18:05:52,486 - INFO - llama_runner.headless_service_manager - ‚úÖ Ollama Proxy server started on http://0.0.0.0:11434/
2025-11-11 18:05:52,487 - INFO - llama_runner.headless_service_manager - Starting LM Studio proxy server...
2025-11-11 18:05:52,487 - INFO - llama_runner.headless_service_manager - ‚úÖ LM Studio Proxy server started on http://0.0.0.0:1234/
2025-11-11 18:05:52,487 - INFO - llama_runner.headless_service_manager - Starting Llama Runner WebUI service on port 8081...
2025-11-11 18:05:52,488 - INFO - llama_runner.headless_service_manager - ‚úÖ Llama Runner WebUI service started on http://0.0.0.0:8081/
2025-11-11 18:05:52,488 - INFO - llama_runner.headless_service_manager -    üåê Access via: http://localhost:8081/
2025-11-11 18:05:52,488 - INFO - llama_runner.headless_service_manager - ‚úÖ All services started successfully. Waiting for shutdown signal...
2025-11-11 18:05:52,488 - INFO - llama_runner.headless_service_manager - 
============================================================
2025-11-11 18:05:52,488 - INFO - llama_runner.headless_service_manager - üåê SERVICES ACCESSIBLES :
2025-11-11 18:05:52,488 - INFO - llama_runner.headless_service_manager - ============================================================
2025-11-11 18:05:52,489 - INFO - llama_runner.headless_service_manager - üè† llama.cpp WebUI: http://localhost:8035/
2025-11-11 18:05:52,489 - INFO - llama_runner.headless_service_manager -    ‚úÖ Direct access - no proxy needed
2025-11-11 18:05:52,489 - INFO - llama_runner.headless_service_manager - üè† Llama Runner WebUI: http://localhost:8081/
2025-11-11 18:05:52,489 - INFO - llama_runner.headless_service_manager - üîó Ollama Proxy: http://localhost:11434/
2025-11-11 18:05:52,489 - INFO - llama_runner.headless_service_manager - üîó LM Studio Proxy: http://localhost:1234/
2025-11-11 18:05:52,489 - INFO - llama_runner.headless_service_manager - ============================================================

2025-11-11 18:12:58,067 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:12:58,068 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:12:58,068 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:12:58,068 - INFO - llama_runner.headless_service_manager - Stopping Ollama proxy...
2025-11-11 18:12:58,068 - INFO - llama_runner.headless_service_manager - Stopping LM Studio proxy...
2025-11-11 18:12:58,068 - INFO - llama_runner.headless_service_manager - Stopping Llama Runner WebUI...
2025-11-11 18:12:58,176 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:12:58,176 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:12:58,176 - INFO - root - All services stopped gracefully
2025-11-11 18:13:03,050 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:03,050 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:03,050 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:03,051 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:03,051 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:03,051 - INFO - root - All services stopped gracefully
2025-11-11 18:13:03,746 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:03,747 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:03,747 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:03,747 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:03,747 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:03,747 - INFO - root - All services stopped gracefully
2025-11-11 18:13:04,042 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:04,042 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:04,042 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:04,042 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:04,042 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:04,042 - INFO - root - All services stopped gracefully
2025-11-11 18:13:04,234 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:04,234 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:04,234 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:04,234 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:04,234 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:04,235 - INFO - root - All services stopped gracefully
2025-11-11 18:13:04,410 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:04,410 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:04,410 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:04,410 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:04,410 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:04,410 - INFO - root - All services stopped gracefully
2025-11-11 18:13:04,601 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:04,602 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:04,602 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:04,602 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:04,602 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:04,602 - INFO - root - All services stopped gracefully
2025-11-11 18:13:04,803 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:04,803 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:04,803 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:04,803 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:04,803 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:04,804 - INFO - root - All services stopped gracefully
2025-11-11 18:13:04,994 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:04,995 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:04,995 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:04,995 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:04,995 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:04,996 - INFO - root - All services stopped gracefully
2025-11-11 18:13:13,754 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:13,754 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:13,754 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:13,754 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:13,754 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:13,755 - INFO - root - All services stopped gracefully
2025-11-11 18:13:14,129 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:14,130 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:14,130 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:14,130 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:14,130 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:14,130 - INFO - root - All services stopped gracefully
2025-11-11 18:13:14,386 - INFO - root - Received signal 2, initiating shutdown
2025-11-11 18:13:14,386 - INFO - root - Shutdown requested, stopping services...
2025-11-11 18:13:14,386 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-11 18:13:14,387 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-11 18:13:14,387 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-11 18:13:14,387 - INFO - root - All services stopped gracefully
2025-11-11 23:41:26,309 - INFO - root - Logging configured for headless mode
2025-11-11 23:41:26,309 - INFO - root - === STARTING HEADLESS SERVICE ===
2025-11-11 23:41:26,310 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 23:41:26,310 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 23:41:26,310 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 23:41:26,310 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 23:41:26,311 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 23:41:26,311 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 23:41:26,311 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 23:41:26,311 - WARNING - llama_runner.services.config_validator - [WARNING] config: No models configured
2025-11-11 23:41:26,312 - WARNING - llama_runner.services.config_validator - Configuration validation passed with 1 warning(s)
2025-11-11 23:41:26,312 - INFO - root - Configuration loaded and validated successfully
2025-11-11 23:41:26,312 - INFO - llama_runner.headless_service_manager - Initializing services for headless mode...
2025-11-11 23:41:26,312 - WARNING - llama_runner.headless_service_manager - Audio section is missing or None in config. Using empty models dict.
2025-11-11 23:41:26,312 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-11 23:41:26,312 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-11 23:41:26,313 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-11 23:41:26,313 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-11 23:41:26,313 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-11 23:41:26,314 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-11 23:41:26,314 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-11 23:41:26,314 - INFO - llama_runner.headless_service_manager - LlamaRunnerManager initialized.
2025-11-11 23:41:26,314 - INFO - llama_runner.headless_service_manager - Ollama Proxy is enabled. Creating server...
2025-11-11 23:41:26,315 - INFO - llama_runner.headless_service_manager - LM Studio Proxy is enabled. Creating server...
2025-11-11 23:41:26,316 - DEBUG - asyncio - Using proactor: IocpProactor
2025-11-11 23:41:26,318 - INFO - root - 
============================================================
2025-11-11 23:41:26,318 - INFO - root - SERVICES ACCESSIBLES :
2025-11-11 23:41:26,318 - INFO - root - ============================================================
2025-11-11 23:41:26,318 - INFO - root - Ollama Proxy: http://127.0.0.1:11434/
2025-11-11 23:41:26,318 - INFO - root - LM Studio Proxy: http://127.0.0.1:1234/
2025-11-11 23:41:26,319 - INFO - root - Dashboard Web: http://127.0.0.1:8080/
2025-11-11 23:41:26,319 - INFO - root - ============================================================

2025-11-11 23:41:26,319 - INFO - root - Starting all services...
2025-11-11 23:41:26,320 - INFO - root - Headless service running. Press Ctrl+C to shutdown.
2025-11-11 23:41:26,321 - INFO - llama_runner.headless_service_manager - Starting all services...
2025-11-11 23:41:26,321 - INFO - llama_runner.headless_service_manager - Starting Ollama proxy server...
2025-11-11 23:41:26,322 - INFO - llama_runner.headless_service_manager - ‚úÖ Ollama Proxy server started on http://0.0.0.0:11434/
2025-11-11 23:41:26,323 - INFO - llama_runner.headless_service_manager - Starting LM Studio proxy server...
2025-11-11 23:41:26,323 - INFO - llama_runner.headless_service_manager - ‚úÖ LM Studio Proxy server started on http://0.0.0.0:1234/
2025-11-11 23:41:26,323 - INFO - llama_runner.headless_service_manager - ‚úÖ All services started successfully. Waiting for shutdown signal...
2025-11-11 23:41:26,323 - INFO - llama_runner.headless_service_manager - 
============================================================
2025-11-11 23:41:26,324 - INFO - llama_runner.headless_service_manager - üåê SERVICES ACCESSIBLES :
2025-11-11 23:41:26,324 - INFO - llama_runner.headless_service_manager - ============================================================
2025-11-11 23:41:26,324 - INFO - llama_runner.headless_service_manager - üè† llama.cpp WebUI: http://localhost:8035/
2025-11-11 23:41:26,324 - INFO - llama_runner.headless_service_manager -    ‚úÖ Direct access - no proxy needed
2025-11-11 23:41:26,324 - INFO - llama_runner.headless_service_manager - üè† Llama Runner WebUI: http://localhost:8081/
2025-11-11 23:41:26,325 - INFO - llama_runner.headless_service_manager - üîó Ollama Proxy: http://localhost:11434/
2025-11-11 23:41:26,325 - INFO - llama_runner.headless_service_manager - üîó LM Studio Proxy: http://localhost:1234/
2025-11-11 23:41:26,326 - INFO - llama_runner.headless_service_manager - ============================================================

2025-11-11 23:43:09,394 - ERROR - root - Error handling /v1/models: 'str' object has no attribute 'get'
Traceback (most recent call last):
  File "F:\llm\llama-runner-async-proxy\llama_runner\lmstudio_proxy_thread.py", line 811, in _list_openai_models_handler
    id_mapping = gguf_metadata.get_model_name_to_id_mapping(all_models_config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\llm\llama-runner-async-proxy\llama_runner\gguf_metadata.py", line 546, in get_model_name_to_id_mapping
    model_path = model_config.get("model_path")
                 ^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'

2025-11-11 23:45:47,723 - ERROR - root - Error handling /v1/models: 'str' object has no attribute 'get'
Traceback (most recent call last):
  File "F:\llm\llama-runner-async-proxy\llama_runner\lmstudio_proxy_thread.py", line 811, in _list_openai_models_handler
    id_mapping = gguf_metadata.get_model_name_to_id_mapping(all_models_config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "F:\llm\llama-runner-async-proxy\llama_runner\gguf_metadata.py", line 546, in get_model_name_to_id_mapping
    model_path = model_config.get("model_path")
                 ^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'get'

2025-11-12 00:21:55,949 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 00:21:55,949 - INFO - root - Shutdown requested, stopping services...
2025-11-12 00:21:55,949 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 00:21:55,949 - INFO - llama_runner.headless_service_manager - Stopping Ollama proxy...
2025-11-12 00:21:55,949 - INFO - llama_runner.headless_service_manager - Stopping LM Studio proxy...
2025-11-12 00:21:56,057 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 00:21:56,058 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 00:21:56,058 - INFO - root - All services stopped gracefully
2025-11-12 00:56:47,313 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 00:56:47,314 - INFO - root - Shutdown requested, stopping services...
2025-11-12 00:56:47,314 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 00:56:47,314 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 00:56:47,314 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 00:56:47,314 - INFO - root - All services stopped gracefully
2025-11-12 00:58:44,145 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 00:58:44,145 - INFO - root - Shutdown requested, stopping services...
2025-11-12 00:58:44,145 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 00:58:44,146 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 00:58:44,146 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 00:58:44,146 - INFO - root - All services stopped gracefully
2025-11-12 01:00:36,568 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 01:00:36,569 - INFO - root - Shutdown requested, stopping services...
2025-11-12 01:00:36,569 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 01:00:36,569 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 01:00:36,569 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 01:00:36,570 - INFO - root - All services stopped gracefully
2025-11-12 01:01:39,813 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 01:01:39,813 - INFO - root - Shutdown requested, stopping services...
2025-11-12 01:01:39,813 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 01:01:39,814 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 01:01:39,814 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 01:01:39,814 - INFO - root - All services stopped gracefully
2025-11-12 01:05:00,889 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 01:05:00,890 - INFO - root - Shutdown requested, stopping services...
2025-11-12 01:05:00,890 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 01:05:00,890 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 01:05:00,890 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 01:05:00,890 - INFO - root - All services stopped gracefully
2025-11-12 01:06:54,280 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 01:06:54,280 - INFO - root - Shutdown requested, stopping services...
2025-11-12 01:06:54,281 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 01:06:54,281 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 01:06:54,281 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 01:06:54,281 - INFO - root - All services stopped gracefully
2025-11-12 01:07:32,643 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 01:07:32,644 - INFO - root - Shutdown requested, stopping services...
2025-11-12 01:07:32,644 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 01:07:32,644 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 01:07:32,644 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 01:07:32,644 - INFO - root - All services stopped gracefully
2025-11-12 01:08:15,326 - INFO - root - Received signal 2, initiating shutdown
2025-11-12 01:08:15,326 - INFO - root - Shutdown requested, stopping services...
2025-11-12 01:08:15,326 - INFO - llama_runner.headless_service_manager - Stopping all services...
2025-11-12 01:08:15,327 - INFO - llama_runner.headless_service_manager - Stopping all Llama runners...
2025-11-12 01:08:15,327 - INFO - llama_runner.headless_service_manager - ‚úÖ All headless services stopped successfully.
2025-11-12 01:08:15,327 - INFO - root - All services stopped gracefully
2025-11-12 01:13:26,533 - INFO - root - Logging configured for headless mode
2025-11-12 01:13:26,533 - INFO - root - === STARTING HEADLESS SERVICE ===
2025-11-12 01:13:26,533 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-12 01:13:26,534 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-12 01:13:26,534 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-12 01:13:26,534 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-12 01:13:26,534 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-12 01:13:26,534 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-12 01:13:26,535 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-12 01:13:26,535 - WARNING - llama_runner.services.config_validator - [WARNING] config: No models configured
2025-11-12 01:13:26,535 - WARNING - llama_runner.services.config_validator - Configuration validation passed with 1 warning(s)
2025-11-12 01:13:26,535 - INFO - root - Configuration loaded and validated successfully
2025-11-12 01:13:26,535 - INFO - llama_runner.headless_service_manager - Initializing services for headless mode...
2025-11-12 01:13:26,535 - WARNING - llama_runner.headless_service_manager - Audio section is missing or None in config. Using empty models dict.
2025-11-12 01:13:26,535 - INFO - root - üîÑ V√©rification de l'existence des fichiers de configuration...
2025-11-12 01:13:26,536 - INFO - root - ‚úÖ V√©rification des r√©pertoires n√©cessaires...
2025-11-12 01:13:26,536 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\config
2025-11-12 01:13:26,536 - INFO - root - ‚úÖ R√©pertoire d√©j√† existant : F:\llm\llama-runner-async-proxy\logs
2025-11-12 01:13:26,536 - INFO - root - üîç Fichier app_config.json existe : True
2025-11-12 01:13:26,536 - INFO - root - üîç Fichier models_config.json existe : True
2025-11-12 01:13:26,537 - INFO - root - ‚úÖ Les fichiers de configuration existent d√©j√†
2025-11-12 01:13:26,537 - INFO - llama_runner.headless_service_manager - LlamaRunnerManager initialized.
2025-11-12 01:13:26,537 - INFO - llama_runner.headless_service_manager - Ollama Proxy is enabled. Creating server...
2025-11-12 01:13:26,537 - INFO - llama_runner.headless_service_manager - LM Studio Proxy is enabled. Creating server...
2025-11-12 01:13:26,541 - DEBUG - asyncio - Using proactor: IocpProactor
2025-11-12 01:13:26,542 - INFO - root - 
============================================================
2025-11-12 01:13:26,543 - INFO - root - SERVICES ACCESSIBLES :
2025-11-12 01:13:26,543 - INFO - root - ============================================================
2025-11-12 01:13:26,543 - INFO - root - Ollama Proxy: http://127.0.0.1:11434/
2025-11-12 01:13:26,543 - INFO - root - LM Studio Proxy: http://127.0.0.1:1234/
2025-11-12 01:13:26,543 - INFO - root - Dashboard Web: http://127.0.0.1:8080/
2025-11-12 01:13:26,543 - INFO - root - ============================================================

2025-11-12 01:13:26,543 - INFO - root - Starting all services...
2025-11-12 01:13:26,544 - INFO - root - Headless service running. Press Ctrl+C to shutdown.
2025-11-12 01:13:26,544 - INFO - llama_runner.headless_service_manager - Starting all services...
2025-11-12 01:13:26,544 - INFO - llama_runner.headless_service_manager - Starting Ollama proxy server...
2025-11-12 01:13:26,545 - INFO - llama_runner.headless_service_manager - ‚úÖ Ollama Proxy server started on http://0.0.0.0:11434/
2025-11-12 01:13:26,545 - INFO - llama_runner.headless_service_manager - Starting LM Studio proxy server...
2025-11-12 01:13:26,546 - INFO - llama_runner.headless_service_manager - ‚úÖ LM Studio Proxy server started on http://0.0.0.0:1234/
2025-11-12 01:13:26,546 - INFO - llama_runner.headless_service_manager - Starting Dashboard API server...
2025-11-12 01:13:26,546 - INFO - llama_runner.services.dashboard_api - Starting Dashboard API server on 0.0.0.0:8585
2025-11-12 01:13:26,546 - INFO - llama_runner.headless_service_manager - ‚úÖ Dashboard API server started on http://0.0.0.0:8585/
2025-11-12 01:13:26,546 - INFO - llama_runner.headless_service_manager - ‚úÖ All services started successfully. Waiting for shutdown signal...
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager - 
============================================================
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager - üåê SERVICES ACCESSIBLES :
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager - ============================================================
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager - üè† llama.cpp WebUI: http://localhost:8035/
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager -    ‚úÖ Direct access - no proxy needed
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager - üè† Llama Runner WebUI: http://localhost:8081/
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager - üîó Ollama Proxy: http://localhost:11434/
2025-11-12 01:13:26,547 - INFO - llama_runner.headless_service_manager - üîó LM Studio Proxy: http://localhost:1234/
2025-11-12 01:13:26,548 - INFO - llama_runner.headless_service_manager - ============================================================

